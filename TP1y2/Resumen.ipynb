{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedimiento básico de uso permanente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos X e y\n",
    "X = df[['feature_cols1', 'feature_cols2', 'feature_cols3']] # o todos sin la Y\n",
    "y = df['target']\n",
    "\n",
    "# Importar paquete, instanciar el estimador y fitear el modelo\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paquetes más comunes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modo simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluar y visualizar correlación de las features para seleccionarlas\n",
    "df.corr()\n",
    "sns.heatmap(df.corr());\n",
    "\n",
    "# Seleccionar modelo\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Elegir hiperparámetros\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "\n",
    "# Preparar los datos en una matriz de features\n",
    "# Crear X e y\n",
    "X = df['cols'] #2 dimensiones\n",
    "y = df['target'] #1 dimensión\n",
    "\n",
    "# Split entrenamiento / testeo para CV\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=1)\n",
    "#Ajustar el modelo a los datos\n",
    "model.fit(Xtrain, ytrain)\n",
    "print (model.coef_)\n",
    "print (model.intercept_)\n",
    "\n",
    "# Predecir\n",
    "# A Mano\n",
    "model.intercept_ + model.coef_*test\n",
    "#Con el método del objeto\n",
    "import numpy as np\n",
    "test_sklearn = np.array(test).reshape(-1,1)\n",
    "model.predict(test_sklearn)\n",
    "#Con método predict\n",
    "ypred = model.predict(Xtest)\n",
    "\n",
    "#Evaluar\n",
    "from sklearn import metrics\n",
    "print ('MAE:', metrics.mean_absolute_error(ytest, ypred))\n",
    "print ('MSE:', metrics.mean_squared_error(ytest, ypred))\n",
    "print ('RMSE:', np.sqrt(metrics.mean_squared_error(ytest, ypred)))\n",
    "print ('R2:', metrics.r2_score(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión polinómica y pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar y funciones\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                         LinearRegression(**kwargs))\n",
    "\n",
    "#Aplicar y visualizar\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()  # plot formatting\n",
    "\n",
    "X_test = np.linspace(-0.1, 1.1, 500).reshape(-1,1)\n",
    "\n",
    "plt.scatter(X.ravel(), y, color='black')\n",
    "axis = plt.axis()\n",
    "for degree in [1, 3, 5]:\n",
    "    y_test = PolynomialRegression(degree).fit(X, y).predict(X_test)\n",
    "    plt.plot(X_test.ravel(), y_test, label='degree={0}'.format(degree))\n",
    "plt.xlim(-0.1, 1.0)\n",
    "plt.ylim(-2, 12)\n",
    "plt.legend(loc='best');\n",
    "\n",
    "#Chequear las variantes usando Validation Curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "degree = np.arange(0, 21)\n",
    "train_score, val_score = validation_curve(PolynomialRegression(), X, y, 'polynomialfeatures__degree'\n",
    "                                          , degree, cv=7)\n",
    "\n",
    "plt.plot(degree, np.mean(train_score, axis=1), color='blue', label='training score')\n",
    "plt.plot(degree, np.mean(val_score, axis=1), color='red', label='validation score')\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scykit más detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos las matrices y el target\n",
    "\n",
    "X = df[[\"column1\".\"column2\",\"columnS\"]]\n",
    "y = df[\"col\"]\n",
    "\n",
    "# Importamos, Instanciamos, Fiteamos, etc..\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X, y)\n",
    "predictions = lm.predict(X)\n",
    "\n",
    "print ('Intercepto=', ' ', model.intercept_)\n",
    "print ('RM=', ' ', model.coef_)\n",
    "print ('R2_train=', ' ', model.score(X, y))\n",
    "\n",
    "# Generamos una función que resume los coeficientes, el intercepto y el R2\n",
    "# \"model\" = objeto con el modelo\n",
    "# \"X\" = matrix de variables independientes\n",
    "\n",
    "def sum_mod(model, X):\n",
    "    a = pd.DataFrame(model.coef_ , X.columns.values)\n",
    "    a = a.append(pd.DataFrame([model.intercept_, model.score(X, y)], index=['Intecept','R2']))\n",
    "    return(a)\n",
    "\n",
    "# Graficamos la variable X contra la variable Y\n",
    "plt.scatter(X, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"RM\")\n",
    "plt.ylabel(\"Valores reales MEDV\")\n",
    "plt.show()\n",
    "\n",
    "# Graficamos el modelo\n",
    "plt.plot(y,y, '-.',c='grey')\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones de MEDV usando RM\")\n",
    "plt.ylabel(\"Valores reales MEDV\")\n",
    "plt.show()\n",
    "\n",
    "# error medio cuadrático\n",
    "print (\"EMC:\", mean_squared_error(y, predictions)) \n",
    "sum_mod(model, X)\n",
    "#comparar ems\n",
    "print (\"Improve: \", mean_squared_error(y, predictions) < prevMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = df[[\"RM\"]]\n",
    "y = targets[[\"MEDV\"]]\n",
    "\n",
    "# Notar la diferencia en el orden de X e y en este caso\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Graficamos los resultados\n",
    "plt.plot(y,y, '-.', c='grey')\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicciones usando RM\")\n",
    "plt.ylabel(\"Valores reales MEDV\")\n",
    "plt.show()\n",
    "\n",
    "# Imprimimos el MSE y un resumen del modelo\n",
    "print (\"EMC:\", mean_squared_error(y, predictions))\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "print ('MAE:', metrics.mean_absolute_error(true, pred))\n",
    "print ('MSE:', metrics.mean_squared_error(true, pred))\n",
    "print ('RMSE:', np.sqrt(metrics.mean_squared_error(true, pred)))\n",
    "print ('R2:', metrics.r2_score(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Mc5wnIQyhkV"
   },
   "source": [
    "Comparando estas métricas:\n",
    "\n",
    "- ** MAE **  es el error promedio.\n",
    "- ** MSE **  \"penaliza\" errores grandes.\n",
    "- ** RMSE **  es interpretable, tiene las mismas unidades  que la \"y\".\n",
    "- ** $R^2$ ** es la proporción de la varianza total de $Y$ explicada por el modelo.\n",
    "\n",
    "Todas estas son ** funciones de pérdida **, queremos minimizarlas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definimos una función que acepta una lista de features y devuelve la prueba RMSE\n",
    "\n",
    "def train_test_rmse(feature_cols):\n",
    "    X = df[feature_cols]\n",
    "    y = df.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_pred = linreg.predict(X_test)\n",
    "    return np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# comparamos diferentes ensambles de features\n",
    "print (train_test_rmse(['feature_1', 'feature_2']))\n",
    "print (train_test_rmse(['feature_1', 'feature_2','feature_3']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
